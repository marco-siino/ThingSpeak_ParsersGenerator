{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marco-siino/ThingSpeak_ParsersGenerator/blob/main/Mistral_7B_Instruct_v0_3_ThingSpeak_Parsers_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ2cK7CovdZy"
      },
      "source": [
        "# Getting Started with `mistral-inference`\n",
        "\n",
        "This notebook will guide you through the process of running Mistral models locally. We will cover the following:\n",
        "- How to chat with Mistral 7B Instruct\n",
        "- How to run Mistral 7B Instruct with function calling capabilities\n",
        "\n",
        "We recommend using a GPU such as the A100 to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6tXvIsQenpI"
      },
      "outputs": [],
      "source": [
        "!pip install mistral-inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf0P4hjrvdZz"
      },
      "source": [
        "## Download Mistral 7B Instruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4ytmRt0WQeMW"
      },
      "outputs": [],
      "source": [
        "!wget https://models.mistralcdn.com/mistral-7b-v0-3/mistral-7B-Instruct-v0.3.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRZg_8wvs5A6"
      },
      "outputs": [],
      "source": [
        "!DIR=$HOME/mistral_7b_instruct_v3 && mkdir -p $DIR && tar -xf mistral-7B-Instruct-v0.3.tar -C $DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CN8gShDf65M"
      },
      "outputs": [],
      "source": [
        "!ls mistral_7b_instruct_v3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and load the model."
      ],
      "metadata": {
        "id": "lawXqkf1QEQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from rouge_score import rouge_scorer\n",
        "\n",
        "from mistral_inference.model import Transformer\n",
        "from mistral_inference.generate import generate\n",
        "\n",
        "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
        "from mistral_common.protocol.instruct.messages import UserMessage\n",
        "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
        "\n",
        "# I can decide which GPU to use on this node on Leonardo.\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
        "torch.cuda.set_device(2)\n",
        "\n",
        "# load tokenizer\n",
        "mistral_tokenizer = MistralTokenizer.from_file(os.path.expanduser(\"~\")+\"/mistral_7b_instruct_v3/tokenizer.model.v3\")\n",
        "\n",
        "# load model\n",
        "model = Transformer.from_folder(os.path.expanduser(\"~\")+\"/mistral_7b_instruct_v3\")"
      ],
      "metadata": {
        "id": "dgd_mYBWttr2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AP5eE0Z5IJ3T",
        "outputId": "052fa461-9ee7-4844-9c41-9e863b6e0f51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 20 01:18:21 2024       \r\n",
            "+---------------------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\r\n",
            "|-----------------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                                         |                      |               MIG M. |\r\n",
            "|=========================================+======================+======================|\r\n",
            "|   0  NVIDIA A100-SXM-64GB            On | 00000000:1D:00.0 Off |                    0 |\r\n",
            "| N/A   42C    P0               60W / 461W|      3MiB / 65536MiB |      0%      Default |\r\n",
            "|                                         |                      |             Disabled |\r\n",
            "+-----------------------------------------+----------------------+----------------------+\r\n",
            "|   1  NVIDIA A100-SXM-64GB            On | 00000000:56:00.0 Off |                    0 |\r\n",
            "| N/A   43C    P0               66W / 476W|      3MiB / 65536MiB |      0%      Default |\r\n",
            "|                                         |                      |             Disabled |\r\n",
            "+-----------------------------------------+----------------------+----------------------+\r\n",
            "|   2  NVIDIA A100-SXM-64GB            On | 00000000:8F:00.0 Off |                    0 |\r\n",
            "| N/A   44C    P0               72W / 452W|  15129MiB / 65536MiB |      2%      Default |\r\n",
            "|                                         |                      |             Disabled |\r\n",
            "+-----------------------------------------+----------------------+----------------------+\r\n",
            "|   3  NVIDIA A100-SXM-64GB            On | 00000000:C8:00.0 Off |                    0 |\r\n",
            "| N/A   43C    P0               62W / 465W|      3MiB / 65536MiB |      0%      Default |\r\n",
            "|                                         |                      |             Disabled |\r\n",
            "+-----------------------------------------+----------------------+----------------------+\r\n",
            "                                                                                         \r\n",
            "+---------------------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                            |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
            "|        ID   ID                                                             Usage      |\r\n",
            "|=======================================================================================|\r\n",
            "|    2   N/A  N/A   1211837      C   ...00/clean-updated-env/bin/python3.10    15126MiB |\r\n",
            "+---------------------------------------------------------------------------------------+\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate the Python code to perform the task."
      ],
      "metadata": {
        "id": "_Q0ZQeyMcUkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =\"\"\"\n",
        "Write the Python code to convert the following JSON FILE using the following JSON SCHEMA:\n",
        "\n",
        "JSON FILE:\n",
        "\n",
        "{\n",
        "    \"channel\": {\n",
        "        \"id\": 1293177,\n",
        "        \"name\": \"San Diego - Estaci\\u00f3n Meteorol\\u00f3gica\",\n",
        "        \"description\": \"San Diego, Cerro Largo, Uruguay\\r\\nEstaci\\u00f3n Meteorol\\u00f3gica Solar\\r\\n(Temp, Hum, Presion, Lluvia, Viento).\\r\\nESP8266, UNO R3, BME 680\\r\\nUpdate Interval - 15 seg\\r\\nhttps://clima.santiago.ovh/\",\n",
        "        \"latitude\": \"-31.9939484\",\n",
        "        \"longitude\": \"-53.9575388\",\n",
        "        \"field1\": \"Temperatura C\\u00b0\",\n",
        "        \"field2\": \"Humedad %\",\n",
        "        \"field3\": \"Pres. Atmosf\\u00e9rica (hPa)\",\n",
        "        \"field4\": \"Gas\",\n",
        "        \"field5\": \"Viento\",\n",
        "        \"field6\": \"Precipitaci\\u00f3n (mm)\",\n",
        "        \"field7\": \"Direcci\\u00f3n del Viento\",\n",
        "        \"field8\": \"UV\",\n",
        "        \"created_at\": \"2021-01-30T16:32:32Z\",\n",
        "        \"updated_at\": \"2024-06-18T14:05:34Z\",\n",
        "        \"elevation\": \"136\",\n",
        "        \"last_entry_id\": 4502987\n",
        "    },\n",
        "    \"feeds\": [\n",
        "        {\n",
        "            \"created_at\": \"2024-06-18T13:33:39Z\",\n",
        "            \"entry_id\": 4502888,\n",
        "            \"field1\": \"17.73\",\n",
        "            \"field2\": \"93.32\",\n",
        "            \"field3\": \"996.29\",\n",
        "            \"field4\": \"103.33\",\n",
        "            \"field5\": \"0.00\",\n",
        "            \"field6\": \"0\",\n",
        "            \"field7\": \"0\",\n",
        "            \"field8\": \"0.74\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "JSON SCHEMA:\n",
        "\n",
        "{\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"sensorId\": {\n",
        "        \"type\": \"string\"\n",
        "      },\n",
        "      \"timestamp\": {\n",
        "        \"type\": \"string\",\n",
        "        \"format\": \"date-time\"\n",
        "      },\n",
        "      \"temperature\": {\n",
        "        \"type\": \"number\"\n",
        "      },\n",
        "      \"unit\": {\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"Celsius\", \"Fahrenheit\"]\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\"sensorId\", \"timestamp\", \"temperature\", \"unit\"]\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4q18v0OxHUL5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chat completion request\n",
        "completion_request = ChatCompletionRequest(messages=[UserMessage(content=prompt)])\n",
        "# encode message\n",
        "tokens = mistral_tokenizer.encode_chat_completion(completion_request).tokens\n",
        "# generate results\n",
        "out_tokens, _ = generate([tokens], model, max_tokens=5000, temperature=0.0, eos_id=mistral_tokenizer.instruct_tokenizer.tokenizer.eos_id)\n",
        "# decode generated tokens\n",
        "result = mistral_tokenizer.instruct_tokenizer.tokenizer.decode(out_tokens[0])\n",
        "print(result+\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTzgpWLXHlOi",
        "outputId": "fa7c0a88-ec2f-4d42-d3d0-e0c93f3ad472"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To convert the given JSON file to the format specified by the JSON schema, we need to create a new JSON object that adheres to the schema's structure. Here's the Python code to achieve this:\n",
            "\n",
            "```python\n",
            "import json\n",
            "import datetime\n",
            "\n",
            "# Given JSON data\n",
            "data = \"\"\"\n",
            "{\n",
            "    \"channel\": {\n",
            "        \"id\": 1293177,\n",
            "        \"name\": \"San Diego - Estación Meteorológica\",\n",
            "        \"description\": \"...\",\n",
            "        \"latitude\": \"-31.9939484\",\n",
            "        \"longitude\": \"-53.9575388\",\n",
            "        \"field1\": \"Temperatura C°\",\n",
            "        \"field2\": \"Humedad %\",\n",
            "        \"field3\": \"Pres. Atmosférica (hPa)\",\n",
            "        \"field4\": \"Gas\",\n",
            "        \"field5\": \"Viento\",\n",
            "        \"field6\": \"Precipitación (mm)\",\n",
            "        \"field7\": \"Dirección del Viento\",\n",
            "        \"field8\": \"UV\",\n",
            "        \"created_at\": \"2021-01-30T16:32:32Z\",\n",
            "        \"updated_at\": \"2024-06-18T14:05:34Z\",\n",
            "        \"elevation\": \"136\",\n",
            "        \"last_entry_id\": 4502987\n",
            "    },\n",
            "    \"feeds\": [\n",
            "        {\n",
            "            \"created_at\": \"2024-06-18T13:33:39Z\",\n",
            "            \"entry_id\": 4502888,\n",
            "            \"field1\": \"17.73\",\n",
            "            \"field2\": \"93.32\",\n",
            "            \"field3\": \"996.29\",\n",
            "            \"field4\": \"103.33\",\n",
            "            \"field5\": \"0.00\",\n",
            "            \"field6\": \"0\",\n",
            "            \"field7\": \"0\",\n",
            "            \"field8\": \"0.74\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\"\"\"\n",
            "\n",
            "# Parse the given JSON data\n",
            "json_data = json.loads(data)\n",
            "\n",
            "# Extract the feed data\n",
            "feed_data = json_data[\"feeds\"][0]\n",
            "\n",
            "# Convert the timestamp to datetime object\n",
            "feed_timestamp = datetime.datetime.strptime(feed_data[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
            "\n",
            "# Create a new JSON object based on the schema\n",
            "new_json = {\n",
            "    \"sensorId\": json_data[\"channel\"][\"id\"],\n",
            "    \"timestamp\": feed_timestamp.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
            "    \"temperature\": float(feed_data[\"field1\"]),\n",
            "    \"unit\": \"Celsius\"  # Assuming the temperature is in Celsius\n",
            "}\n",
            "\n",
            "# Print the new JSON object\n",
            "print(json.dumps(new_json))\n",
            "```\n",
            "\n",
            "This code extracts the feed data from the given JSON object, converts the timestamp to the format required by the schema, and creates a new JSON object based on the schema's structure. The resulting JSON object only contains the required fields as specified by the schema.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import datetime\n",
        "\n",
        "# Given JSON data\n",
        "data = \"\"\"\n",
        "{\n",
        "    \"channel\": {\n",
        "        \"id\": 1293177,\n",
        "        \"name\": \"San Diego - Estación Meteorológica\",\n",
        "        \"description\": \"...\",\n",
        "        \"latitude\": \"-31.9939484\",\n",
        "        \"longitude\": \"-53.9575388\",\n",
        "        \"field1\": \"Temperatura C°\",\n",
        "        \"field2\": \"Humedad %\",\n",
        "        \"field3\": \"Pres. Atmosférica (hPa)\",\n",
        "        \"field4\": \"Gas\",\n",
        "        \"field5\": \"Viento\",\n",
        "        \"field6\": \"Precipitación (mm)\",\n",
        "        \"field7\": \"Dirección del Viento\",\n",
        "        \"field8\": \"UV\",\n",
        "        \"created_at\": \"2021-01-30T16:32:32Z\",\n",
        "        \"updated_at\": \"2024-06-18T14:05:34Z\",\n",
        "        \"elevation\": \"136\",\n",
        "        \"last_entry_id\": 4502987\n",
        "    },\n",
        "    \"feeds\": [\n",
        "        {\n",
        "            \"created_at\": \"2024-06-18T13:33:39Z\",\n",
        "            \"entry_id\": 4502888,\n",
        "            \"field1\": \"17.73\",\n",
        "            \"field2\": \"93.32\",\n",
        "            \"field3\": \"996.29\",\n",
        "            \"field4\": \"103.33\",\n",
        "            \"field5\": \"0.00\",\n",
        "            \"field6\": \"0\",\n",
        "            \"field7\": \"0\",\n",
        "            \"field8\": \"0.74\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Parse the given JSON data\n",
        "json_data = json.loads(data)\n",
        "\n",
        "# Extract the feed data\n",
        "feed_data = json_data[\"feeds\"][0]\n",
        "\n",
        "# Convert the timestamp to datetime object\n",
        "feed_timestamp = datetime.datetime.strptime(feed_data[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "# Create a new JSON object based on the schema\n",
        "new_json = {\n",
        "    \"sensorId\": json_data[\"channel\"][\"id\"],\n",
        "    \"timestamp\": feed_timestamp.strftime(\"%Y-%m-%dT%H:%M:%S\"),\n",
        "    \"temperature\": float(feed_data[\"field1\"]),\n",
        "    \"unit\": \"Celsius\"  # Assuming the temperature is in Celsius\n",
        "}\n",
        "\n",
        "# Print the new JSON object\n",
        "print(json.dumps(new_json))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhDdCH4oH4AX",
        "outputId": "0b895b5d-8b6e-4773-fc40-f349e161325c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"sensorId\": 1293177, \"timestamp\": \"2024-06-18T13:33:39\", \"temperature\": 17.73, \"unit\": \"Celsius\"}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "ZQ2cK7CovdZy",
        "42H-evLTO83s"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}